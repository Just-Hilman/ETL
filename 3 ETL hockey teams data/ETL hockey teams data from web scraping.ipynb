{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "- In this project I will use webscraping to get hockey teams data\n",
    "- Once I've got all the necessary data, I'll do Extract, Transform, and Load on the data i've collected."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries\n",
    "I using several python libraries for this project:\n",
    "- pandas\n",
    "- requests\n",
    "- BeautifulSoup\n",
    "- html5lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Data Using Web Scraping\n",
    "The book list webpage https://www.scrapethissite.com/ provide information about list of hockey teams as well as their Team Name, Year, Wins, Losses, and etc. We will scrape the data for all teams in the list and store it in csv files."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Webpage Contents\n",
    "Gather the contents of the webpage and convert into text format using the requests library and assign it to variable html_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scraping the Data\n",
    "Using the contents and beautiful soup load the data from webpage into pandas dataframe.\n",
    "\n",
    "Using BeautifulSoup parse the contents of the webpage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create hockey_teams_data dataframe will be used for store the data, with the columns as well as displayed below\n",
    "hockey_teams_data = pd.DataFrame(columns=[\"Team Name\", \"Year\", \"Wins\", \"Losses\", \"OT Losses\", \"Win %\", \"Goals For (GF)\", \"Goals Againts (GA)\", \"+/-\"])\n",
    "\n",
    "# Looping to find the all page data we will scrape\n",
    "for i in range(1, 25):\n",
    "    url = 'https://www.scrapethissite.com/pages/forms/?page_num='+str(i)\n",
    "    html_data = requests.get(url).text\n",
    "\n",
    "    soup = BeautifulSoup(html_data, \"html.parser\")\n",
    "    table = soup.find('table')\n",
    "\n",
    "    # Remove table head since I don't need it right now, I'll add the table head with pandas dataframe we're create before\n",
    "    remove_head = table.find('tr') #<---- find only the first element 'tr' in table\n",
    "    remove_head.decompose() #<---- remove that element\n",
    "\n",
    "    # Looping to find all table row and table column\n",
    "    for row in table.find_all('tr'):\n",
    "        cols = row.find_all('td')\n",
    "        team_name = cols[0].text.strip()\n",
    "        year = cols[1].text.strip()\n",
    "        wins = cols[2].text.strip()\n",
    "        losses = cols[3].text.strip()\n",
    "        ot_losses = cols[4].text.strip()\n",
    "        win_rate = cols[5].text.strip()\n",
    "        gf = cols[6].text.strip()\n",
    "        ga = cols[7].text.strip()\n",
    "        diff = cols[8].text.strip()\n",
    "        hockey_teams_data = hockey_teams_data.append({\"Team Name\": team_name, \"Year\": year, \"Wins\": wins, \"Losses\": losses, \"OT Losses\": ot_losses, \"Win %\": win_rate, \"Goals For (GF)\": gf, \"Goals Againts (GA)\": ga, \"+/-\": diff}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hockey_teams_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export Data\n",
    "Load the `pandas` dataframe created above into a CSV file named `hockey_teams_data.csv` using the `to_csv()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hockey_teams_data.to_csv(\"hockey_teams_data.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ETL\n",
    "- Read CSV file\n",
    "- Extract data\n",
    "- Transform data\n",
    "- Save the transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from datetime import datetime"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpfile = \"tmpfile.tmp\"                     # file used to store all extracted data\n",
    "logfile = \"logfile.txt\"                     # all event logs will be stored in this file\n",
    "targetfile = \"transformed_data.csv\"         # file where transformed data is stored"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_from_csv(file_to_process):\n",
    "    dataframe = pd.read_csv(file_to_process)\n",
    "    return dataframe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract():\n",
    "    extracted_data = pd.DataFrame(columns=[\"Team Name\", \"Year\", \"Wins\", \"Losses\", \"OT Losses\", \"Win %\", \"Goals For (GF)\", \"Goals Againts (GA)\", \"+/-\"]) #create an empty dataframe to hold extracted_data\n",
    "\n",
    "    for csvfile in glob.glob(\".csv\"):\n",
    "        extracted_data = extracted_data.append(extract_from_csv(csvfile), ignore_index=True)\n",
    "    return extracted_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform\n",
    "The users have made a little mistake in inputting the data, and they now realize that something gets worst if they don't get things back the right way.\n",
    "- The `year` column should be start at 2000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(data):\n",
    "    data['Year'] = data['Year'] + 10\n",
    "    return data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load (targetfile, data_to_load):\n",
    "    data_to_load.to_csv(targetfile)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(message):\n",
    "    timestamp_format = '%Y-%h-%d-%H:%M:%S' #Year-Monthname-Day-Hour-Minute-Second\n",
    "    now = datetime.now() #get current timestamp\n",
    "    timestamp = now.strftime(timestamp_format)\n",
    "    with open(\"logfile.txt\", \"a\") as f:\n",
    "        f.write(timestamp + ',' + message + '\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running ETL Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "log(\"ETL Job Started\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Wins</th>\n",
       "      <th>Losses</th>\n",
       "      <th>OT Losses</th>\n",
       "      <th>Win %</th>\n",
       "      <th>Goals For (GF)</th>\n",
       "      <th>Goals Againts (GA)</th>\n",
       "      <th>+/-</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Team Name, Year, Wins, Losses, OT Losses, Win %, Goals For (GF), Goals Againts (GA), +/-]\n",
       "Index: []"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log(\"Extract phase Started\")\n",
    "extracted_data = extract()\n",
    "log(\"Extract phase Ended\")\n",
    "extracted_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
